{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9b8f2b6",
   "metadata": {
    "papermill": {
     "duration": 0.003277,
     "end_time": "2025-08-20T00:40:00.753440",
     "exception": false,
     "start_time": "2025-08-20T00:40:00.750163",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# things to change  \n",
    "- custom batching to put samples of the same category next to each other  \n",
    "- add more samples  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9772713f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:40:00.759330Z",
     "iopub.status.busy": "2025-08-20T00:40:00.759083Z",
     "iopub.status.idle": "2025-08-20T00:40:00.768054Z",
     "shell.execute_reply": "2025-08-20T00:40:00.767267Z"
    },
    "papermill": {
     "duration": 0.013116,
     "end_time": "2025-08-20T00:40:00.769271",
     "exception": false,
     "start_time": "2025-08-20T00:40:00.756155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing data.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile data.py\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "predictor_labels = 'Reverse,Forward,One_Shot_Intent,Loop_Intent,Drum,Percussion,Kick,Clap,Hi Hat'.split(',')\n",
    "features_labels = ['centroid_mean', 'bandwidth_mean', 'bandwidth_low', 'bandwidth_low_10', 'bandwidth_high', 'bandwidth_high_90', 'bandwidth_range', 'onset_strength_mean', 'onset_strength_max', 'zcr_mean', 'onset_strength_ratio', 'onset_frame_count']\n",
    "gru_labels = ['centroid', 'bandwidth', 'zcr', 'onset_strength']\n",
    "\n",
    "class MultiModalDataset(Dataset):\n",
    "    def __init__(self, index_pos, images, energies, spectrums, features, labels):\n",
    "        self.index_pos = index_pos\n",
    "        self.images = images\n",
    "        self.energies = energies\n",
    "        self.spectrums = spectrums\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.index_pos[idx],\n",
    "                self.images[idx],\n",
    "                self.features[idx],\n",
    "                self.spectrums[idx],\n",
    "                self.energies[idx],\n",
    "                self.labels[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fc9144",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:40:00.774921Z",
     "iopub.status.busy": "2025-08-20T00:40:00.774700Z",
     "iopub.status.idle": "2025-08-20T00:40:00.782476Z",
     "shell.execute_reply": "2025-08-20T00:40:00.781881Z"
    },
    "papermill": {
     "duration": 0.012084,
     "end_time": "2025-08-20T00:40:00.783569",
     "exception": false,
     "start_time": "2025-08-20T00:40:00.771485",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing model.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile model.py\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "dropout_val_1 = 0.35 *(0.9)\n",
    "dropout_val_2 = 0.5\n",
    "neuron_count = 32\n",
    "gnu_neuron_count = 64\n",
    "\n",
    "\n",
    "class CNNImagesBranch(nn.Module):\n",
    "    def __init__(self, input_channels, dropout_val=dropout_val_1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, int(neuron_count), kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(dropout_val),\n",
    "\n",
    "            nn.Conv2d(int(neuron_count), int(neuron_count * 2), kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count * 2)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(dropout_val),\n",
    "\n",
    "            nn.Conv2d(int(neuron_count * 2), int(neuron_count * 4), kernel_size=3, padding=0),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count * 4)),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(dropout_val),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, channels, H, W)\n",
    "        if x.shape[-1] == 2:\n",
    "            x = x.permute(0, 1, 4, 2, 3)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B*T, C, H, W)\n",
    "        x = self.cnn(x)\n",
    "        x = x.reshape(B, T, -1)  # restore time dimension\n",
    "        return x\n",
    "\n",
    "class CNNSpectrumsBranch(nn.Module):\n",
    "    def __init__(self, input_channels, dropout_val=dropout_val_1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, int(neuron_count), kernel_size=(3,3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count)),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout_val),\n",
    "\n",
    "            nn.Conv2d(int(neuron_count), int(neuron_count * 2), kernel_size=(3,3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count * 2)),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout_val),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, channels, H, W)\n",
    "        if x.shape[3] == 5:\n",
    "            x = x.permute(0, 2, 3, 1, 4)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B*T, C, H, W)\n",
    "        #x = x.permute(0, 3, 2, 1)\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(B, T, -1)  # restore time dimension\n",
    "        return x\n",
    "\n",
    "class CNNEnergiesBranch(nn.Module):\n",
    "    def __init__(self, input_channels, dropout_val=dropout_val_1):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, int(neuron_count), kernel_size=(3,3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count)),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout_val),\n",
    "\n",
    "            nn.Conv2d(int(neuron_count), int(neuron_count * 2), kernel_size=(3,3), padding=1),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.BatchNorm2d(int(neuron_count * 2)),\n",
    "            nn.MaxPool2d((1, 2)),\n",
    "            nn.Dropout(dropout_val),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, channels, H, W)\n",
    "        if x.shape[3] == 3:\n",
    "            x= x.permute(0, 2, 3, 1, 4)\n",
    "        B, T, C, H, W = x.shape\n",
    "        x = x.view(B*T, C, H, W)\n",
    "        x = self.cnn(x)\n",
    "        x = x.view(B, T, -1)  # restore time dimension\n",
    "        return x\n",
    "\n",
    "\n",
    "class FeaturesBranch(nn.Module):\n",
    "    def __init__(self, input_dim, dropout_val=dropout_val_1):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_dim, int(neuron_count * 2)),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(dropout_val)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        #print(f'x shape from features branch: {x}')\n",
    "        return self.fc(x)\n",
    "\n",
    "\n",
    "class GRUBranch(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim=int(gnu_neuron_count), dropout_val=dropout_val_1, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True, bidirectional=True, dropout=dropout_val)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch, time, feature_dim)\n",
    "        output, _ = self.gru(x)\n",
    "        # Take last time step\n",
    "        return output[:, -1, :]\n",
    "\n",
    "def custom_collate_fn(batch):\n",
    "    idx = images = [torch.tensor(item[0]).int() for item in batch]\n",
    "    images = [item[1].float() for item in batch]\n",
    "    features = torch.stack([item[2] for item in batch])\n",
    "    spectrums = [item[3].float() for item in batch]\n",
    "    energies = [item[4].float() for item in batch]\n",
    "    labels = torch.stack([torch.tensor(item[5]) for item in batch])\n",
    "    return {\n",
    "        'index_pos': idx,\n",
    "        'images': images,\n",
    "        'features': features,\n",
    "        'spectrums': spectrums,\n",
    "        'energies': energies,\n",
    "        'labels': labels\n",
    "    }\n",
    "\n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, img_shape, energy_shape, spectrum_shape, feature_dim, output_dim, dropout_val_1=0.35, dropout_val_2=0.5):\n",
    "        super().__init__()\n",
    "\n",
    "        # CNN branches\n",
    "        self.images_cnn = CNNImagesBranch(img_shape[0], dropout_val_1)\n",
    "        self.energies_cnn = CNNEnergiesBranch(energy_shape[0], dropout_val_1)\n",
    "        self.spectrums_cnn = CNNSpectrumsBranch(spectrum_shape[0], dropout_val_1)\n",
    "\n",
    "        # GRU branches\n",
    "        self.images_gru = GRUBranch(self._cnn_output_dim(self.images_cnn, img_shape), dropout_val=dropout_val_1)\n",
    "        self.energies_gru = GRUBranch(self._cnn_output_dim(self.energies_cnn, energy_shape), dropout_val=dropout_val_1)\n",
    "        self.spectrums_gru = GRUBranch(self._cnn_output_dim(self.spectrums_cnn, spectrum_shape), dropout_val=dropout_val_1)\n",
    "\n",
    "        # Feature branch\n",
    "        self.features_branch = FeaturesBranch(feature_dim, dropout_val_1)\n",
    "\n",
    "        # Final layers\n",
    "        total_concat_dim = 2*int(gnu_neuron_count) + 2*int(gnu_neuron_count) + 2*int(gnu_neuron_count) + int(neuron_count*2)  # three GRUs (bidirectional 64), plus feature 64\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(total_concat_dim, int(gnu_neuron_count * 4)),\n",
    "            nn.LeakyReLU(0.01),\n",
    "            nn.Dropout(dropout_val_2),\n",
    "            nn.Linear(int(gnu_neuron_count * 4), output_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.bidirectional = True\n",
    "\n",
    "    def _cnn_output_dim(self, cnn_module, input_shape):\n",
    "        # Dummy forward pass to find flattened CNN feature size\n",
    "        #print(f'cnn_output_dim shape: {input_shape} module: {cnn_module}')\n",
    "        if len(input_shape) == 3:\n",
    "            C, H, W = input_shape\n",
    "            x = torch.zeros(1, 1, C, H, W)\n",
    "        elif len(input_shape) == 2:\n",
    "            C, W = input_shape\n",
    "            x = torch.zeros(1, 1, C, 1, W)  # Will be reshaped inside CNN forward anyway\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected input_shape: {input_shape}\")\n",
    "        #print(x.shape)\n",
    "        out = cnn_module(x)  # make shape (1, C, H, W) or (1, C, W)\n",
    "        return out.view(1, -1).size(1)\n",
    "\n",
    "    def get_bidirectional_last_layer(self, h):\n",
    "        if self.bidirectional:\n",
    "            # Assume 2-layer bidirectional GRU: (4, B, H), for example\n",
    "            # Take last layer's forward and backward states\n",
    "            forward = h[-2, :, :]  # last forward layer\n",
    "            backward = h[-1, :, :]  # last backward layer\n",
    "            return torch.cat([forward, backward], dim=1)\n",
    "\n",
    "    def forward(self, images, features, spectrums, energies):\n",
    "        # All 4 inputs are:\n",
    "        # - images:    List[Tensor] each of shape (T_i, C, H, W)\n",
    "        # - features:  Tensor of shape (B, feature_dim)\n",
    "        # - spectrums: List[Tensor] each of shape (T_i, C, H, W)\n",
    "        # - energies:  List[Tensor] each of shape (T_i, C, H, W)\n",
    "\n",
    "        batch_img_feat = []\n",
    "        batch_spec_feat = []\n",
    "        batch_energy_feat = []\n",
    "    \n",
    "        for img_seq in images:\n",
    "            img_seq = img_seq.unsqueeze(0)  # (1, T, C, H, W)\n",
    "            out = self.images_cnn(img_seq)  # (1, T, feat)\n",
    "            out = out.squeeze(0)            # (T, feat)\n",
    "            batch_img_feat.append(out)\n",
    "    \n",
    "        for spec_seq in spectrums:\n",
    "            spec_seq = spec_seq.unsqueeze(0)\n",
    "            spec_seq = spec_seq.unsqueeze(0)\n",
    "            out = self.spectrums_cnn(spec_seq)\n",
    "            out = out.squeeze(0)\n",
    "            batch_spec_feat.append(out)\n",
    "    \n",
    "        for energy_seq in energies:\n",
    "            energy_seq = energy_seq.unsqueeze(0)\n",
    "            energy_seq = energy_seq.unsqueeze(0)\n",
    "            out = self.energies_cnn(energy_seq)\n",
    "            out = out.squeeze(0)\n",
    "            batch_energy_feat.append(out)\n",
    "    \n",
    "        # Now GRUs â€” we use pack_sequence to handle variable lengths\n",
    "        packed_img = nn.utils.rnn.pack_sequence(batch_img_feat, enforce_sorted=False)\n",
    "        packed_spec = nn.utils.rnn.pack_sequence(batch_spec_feat, enforce_sorted=False)\n",
    "        packed_energy = nn.utils.rnn.pack_sequence(batch_energy_feat, enforce_sorted=False)\n",
    "    \n",
    "        _, h_img = self.images_gru.gru(packed_img)\n",
    "        _, h_spec = self.spectrums_gru.gru(packed_spec)\n",
    "        _, h_energy = self.energies_gru.gru(packed_energy)\n",
    "    \n",
    "        # h_n shape: (num_layers * num_directions, batch, hidden_dim)\n",
    "        # We want to concatenate final forward and backward layers\n",
    "    \n",
    "        img_feat = self.get_bidirectional_last_layer(h_img)\n",
    "        spec_feat = self.get_bidirectional_last_layer(h_spec)\n",
    "        energy_feat = self.get_bidirectional_last_layer(h_energy)\n",
    "    \n",
    "        # Static features branch\n",
    "        feat_out = self.features_branch(features)  # (B, 64)\n",
    "    \n",
    "        # Merge\n",
    "        merged = torch.cat([img_feat, spec_feat, energy_feat, feat_out], dim=1)\n",
    "    \n",
    "        # Final classifier\n",
    "        out = self.fc(merged)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43218246",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:40:00.788873Z",
     "iopub.status.busy": "2025-08-20T00:40:00.788703Z",
     "iopub.status.idle": "2025-08-20T00:40:00.796091Z",
     "shell.execute_reply": "2025-08-20T00:40:00.795445Z"
    },
    "papermill": {
     "duration": 0.011336,
     "end_time": "2025-08-20T00:40:00.797127",
     "exception": false,
     "start_time": "2025-08-20T00:40:00.785791",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile trainer.py\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.distributed as dist\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, roc_auc_score\n",
    "import torch\n",
    "import torch.distributed\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report, f1_score, accuracy_score, roc_auc_score\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "def arr_avg(arr, highest_val, threshold):\n",
    "    l = len(arr)\n",
    "    if l == 3:\n",
    "        summed_vals = 0\n",
    "        for i in arr:\n",
    "            summed_vals += i\n",
    "        avg = summed_vals/l\n",
    "        if highest_val - avg > threshold:\n",
    "            #print(f'highest val: {highest_val} current val: {summed_vals/l}')\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader, criterion, device, world_size, train_loss, train_acc, train_auc, epoch, epochs, cached_results, best_acc, checkpoint_epoch, max_mem):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            images = [x.to(device) for x in batch['images']]\n",
    "            spectrums = [x.to(device) for x in batch['spectrums']]\n",
    "            energies = [x.to(device) for x in batch['energies']]\n",
    "            features = batch['features'].to(device)\n",
    "            labels = batch['labels'].float().to(device)\n",
    "    \n",
    "            outputs = model(images, features, spectrums, energies)\n",
    "            outputs = outputs.float()  # ensure correct dtype\n",
    "    \n",
    "            loss = criterion(outputs, labels)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "            # Save for metrics\n",
    "            all_labels.append(labels.cpu())\n",
    "            all_preds.append(outputs.cpu())\n",
    "\n",
    "    # Concatenate all batches\n",
    "    all_labels = torch.cat(all_labels).numpy()\n",
    "    all_preds = torch.cat(all_preds).numpy()\n",
    "\n",
    "    # Compute accuracy\n",
    "    preds_binary = (all_preds >= 0.5).astype(int)\n",
    "    acc = accuracy_score(all_labels, preds_binary)\n",
    "\n",
    "    # Compute AUC (handle single-class edge case)\n",
    "    try:\n",
    "        auc = roc_auc_score(all_labels, all_preds)\n",
    "    except ValueError:\n",
    "        auc = float('nan')  # or 0.0 or log warning if desired\n",
    "\n",
    "    avg_loss = total_loss / len(val_dataloader)\n",
    "    \n",
    "\n",
    "    metrics = torch.tensor(\n",
    "        [train_loss, train_acc, train_auc, avg_loss, acc, auc],\n",
    "        dtype=torch.float32,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    outs = [torch.zeros_like(metrics) for _ in range(world_size)]\n",
    "    dist.all_gather(outs, metrics)\n",
    "\n",
    "    gathered_metrics = [o.cpu().numpy().tolist() for o in outs]\n",
    "    \n",
    "    if dist.get_rank() == 0:\n",
    "        metrics_array = torch.stack(outs)        # shape: [world_size, num_metrics]\n",
    "        avg_metrics = metrics_array.mean(dim=0)\n",
    "\n",
    "        print('-' * 60)\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}\")\n",
    "        print(f\"Train Loss: {avg_metrics[0]:.4f} Train acc: {avg_metrics[1]:.4f} Train AUC: {avg_metrics[2]:.4f}\")\n",
    "        print(f'Val   Loss: {avg_metrics[3]:.4f} Val   acc: {avg_metrics[4]:.4f} Val   AUC: {avg_metrics[5]:.4f}')\n",
    "\n",
    "        cached_results.append(avg_metrics[4])\n",
    "        if len(cached_results) > 3:\n",
    "            cached_results.pop(0)\n",
    "\n",
    "        if avg_metrics[4] > best_acc:\n",
    "            checkpoint_epoch = epoch\n",
    "            torch.save(model.module.state_dict(), 'best_weights.pth')\n",
    "            print(f'Accuracy increased to {avg_metrics[4]:.4f} from {best_acc:.4f}. Saved copy of new weights')\n",
    "            best_acc = avg_metrics[4]\n",
    "            cached_results.clear()\n",
    "    torch.distributed.barrier()\n",
    "    max_mem = max_mem / (1024**3)\n",
    "    print(f'max mem used on gpu{device}: {max_mem:.4f}GB')\n",
    "    \"\"\"if arr_avg(cached_results, best_acc, 0.25):\n",
    "        model.load_state_dict(torch.load('/kaggle/working/best_weights.pth', weights_only=True))\n",
    "        print('acc has fallen by more than 25%. Reloading best weights')\n",
    "        checkpoint_epoch = epoch\n",
    "        cached_results.clear()\"\"\"\n",
    "        \n",
    "    \n",
    "    return best_acc, checkpoint_epoch\n",
    "\n",
    "\n",
    "def compute_metrics(preds, targets, threshold=0.5):\n",
    "    preds_bin = (preds > threshold).astype(int)\n",
    "    acc = accuracy_score(targets, preds_bin)\n",
    "    auc = roc_auc_score(targets, preds)\n",
    "    return acc, auc\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(\n",
    "        self,\n",
    "        model: nn.Module,\n",
    "        train_dataloader: DataLoader,\n",
    "        val_dataloader: DataLoader,\n",
    "        device,\n",
    "        world_size\n",
    "    ) -> None:\n",
    "        self.model = model\n",
    "        self.train_dataloader = train_dataloader\n",
    "        self.val_dataloader = val_dataloader\n",
    "        self.device = device\n",
    "        self.world_size = world_size\n",
    "\n",
    "    def _save_checkpoint(self):\n",
    "        ckp = self.model.module.state_dict()\n",
    "        torch.save(ckp, \"checkpoint.pt\")\n",
    "\n",
    "    def train(self, epochs: int, train_sampler, optimizer):\n",
    "        self.model.to(self.device)\n",
    "        torch.cuda.reset_peak_memory_stats()\n",
    "        \n",
    "        cached_results = []\n",
    "        best_acc = 0\n",
    "        checkpoint_epoch = 0\n",
    "        \n",
    "        criterion = nn.BCELoss()  # or BCEWithLogitsLoss if you remove sigmoid from model output\n",
    "    \n",
    "        for epoch in range(epochs):\n",
    "            self.model.train()\n",
    "            train_sampler.set_epoch(epoch)\n",
    "            total_loss = 0.0\n",
    "            all_preds = []\n",
    "            all_labels = []\n",
    "    \n",
    "            for batch in self.train_dataloader:\n",
    "                images = [x.to(self.device) for x in batch['images']]\n",
    "                spectrums = [x.to(self.device) for x in batch['spectrums']]\n",
    "                energies = [x.to(self.device) for x in batch['energies']]\n",
    "                features = batch['features'].to(self.device)\n",
    "                labels = batch['labels'].float().to(self.device)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                outputs = self.model(images, features, spectrums, energies)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                total_loss += loss.item()\n",
    "    \n",
    "                all_labels.append(labels.cpu())\n",
    "                all_preds.append(outputs.cpu())\n",
    "    \n",
    "            # Concatenate all batches\n",
    "            all_labels = torch.cat(all_labels).detach().numpy()\n",
    "            all_preds = torch.cat(all_preds).detach().numpy()\n",
    "        \n",
    "            # Compute accuracy\n",
    "            preds_binary = (all_preds >= 0.5).astype(int)\n",
    "            acc = accuracy_score(all_labels, preds_binary)\n",
    "    \n",
    "            try:\n",
    "                auc = roc_auc_score(all_labels, all_preds)\n",
    "            except ValueError:\n",
    "                auc = float('nan')  # or 0.0 or log warning if desired\n",
    "    \n",
    "            avg_train_loss = total_loss / len(self.train_dataloader)\n",
    "            max_mem = torch.cuda.max_memory_allocated()\n",
    "            if self.val_dataloader:\n",
    "                #val_loss, val_acc, val_auc = evaluate(self.model, self.val_dataloader, criterion, self.device, self.world_size, avg_train_loss, acc, auc)\n",
    "                best_acc, checkpoint_epoch = evaluate(self.model, self.val_dataloader, criterion, self.device, self.world_size, avg_train_loss, acc, auc, epoch, epochs, cached_results, best_acc, checkpoint_epoch, max_mem)\n",
    "\n",
    "        if dist.get_rank() == 0:\n",
    "            print(f'Best Epoch : {checkpoint_epoch + 1} - accuracy: {best_acc}')\n",
    "        time.sleep(5)\n",
    "\n",
    "    def infer_best_model(self, predictor_labels, y_test):\n",
    "        #reload model\n",
    "        map_location = torch.device(self.device) if not isinstance(self.device, torch.device) else self.device\n",
    "        #state_dict = torch.load('/kaggle/input/best-model/pytorch/default/1/best_weights.pth', map_location=map_location)\n",
    "        state_dict = torch.load('/kaggle/working/best_weights.pth', map_location=map_location, weights_only=True)\n",
    "        if isinstance(self.model, torch.nn.parallel.DistributedDataParallel):\n",
    "            self.model.module.load_state_dict(state_dict, strict=True)\n",
    "        else:\n",
    "            self.model.load_state_dict(state_dict, strict=True)\n",
    "        \n",
    "        self.model.eval()\n",
    "        gpu_preds = []\n",
    "        \n",
    "        #get preds from test data\n",
    "        with torch.no_grad():\n",
    "            for batch in self.val_dataloader:\n",
    "                indexes = [x.to(self.device) for x in batch['index_pos']]\n",
    "                images = [x.to(self.device) for x in batch['images']]\n",
    "                spectrums = [x.to(self.device) for x in batch['spectrums']]\n",
    "                energies = [x.to(self.device) for x in batch['energies']]\n",
    "                features = batch['features'].to(self.device)\n",
    "\n",
    "                idx = torch.tensor(\n",
    "                    indexes,\n",
    "                    dtype=torch.int,\n",
    "                    device=self.device\n",
    "                )\n",
    "                idx = idx.unsqueeze(1)\n",
    "\n",
    "                outputs = self.model(images, features, spectrums, energies)\n",
    "                outputs = outputs.float()  # ensure correct dtype\n",
    "                outputs = torch.cat((idx, outputs), axis=1)\n",
    "    \n",
    "                gpu_preds.append(outputs.cpu())\n",
    "                \n",
    "        gpu_preds = torch.cat(gpu_preds).numpy()\n",
    "        ids = gpu_preds[:, 0].astype(int)\n",
    "        preds = (gpu_preds[:, 1:] >= 0.55).astype(int)\n",
    "        \n",
    "        # recombine\n",
    "        gpu_preds = np.column_stack((ids, preds))\n",
    "\n",
    "        preds_tensor = torch.tensor(\n",
    "            gpu_preds,\n",
    "            dtype=torch.float32,\n",
    "            device=self.device\n",
    "        )\n",
    "        all_preds = [torch.zeros_like(preds_tensor) for _ in range(self.world_size)]\n",
    "        dist.all_gather(all_preds, preds_tensor)\n",
    "         \n",
    "        if dist.get_rank() == 0:\n",
    "            gathered_preds = torch.cat(all_preds, axis=0)\n",
    "            gathered_preds = gathered_preds.cpu().numpy()\n",
    "\n",
    "            labs = ['id', 'file_path', 'file_name'] + predictor_labels\n",
    "            y_meta = y_test[['id', 'file_path', 'file_name']].copy()\n",
    "            \n",
    "            pred_df = pd.DataFrame(gathered_preds, columns= ['id'] + predictor_labels)            \n",
    "            pred_df = joined = pd.merge(y_meta, pred_df, on='id', how='left')\n",
    "            \n",
    "            #f1 score\n",
    "            print(f\"F1 Score: {f1_score(y_test[predictor_labels], pred_df[predictor_labels], average='weighted')}\")\n",
    "            print(classification_report(y_test[predictor_labels], pred_df[predictor_labels], target_names=predictor_labels))\n",
    "            \n",
    "            #write excel file\n",
    "            with pd.ExcelWriter(\"even_loop_oneshot_2.xlsx\") as writer:\n",
    "                pred_df.to_excel(writer, sheet_name=\"predicted values\", index=False)\n",
    "                y_test[labs].to_excel(writer, sheet_name=\"actual values\", index=False)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a95766a8",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-08-20T00:40:00.803530Z",
     "iopub.status.busy": "2025-08-20T00:40:00.803337Z",
     "iopub.status.idle": "2025-08-20T00:40:00.810835Z",
     "shell.execute_reply": "2025-08-20T00:40:00.809884Z"
    },
    "papermill": {
     "duration": 0.01285,
     "end_time": "2025-08-20T00:40:00.812306",
     "exception": false,
     "start_time": "2025-08-20T00:40:00.799456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ddp.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ddp.py\n",
    "\n",
    "import joblib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.distributed import init_process_group, destroy_process_group\n",
    "import torch.multiprocessing as mp\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "from data import MultiModalDataset, predictor_labels, features_labels\n",
    "from model import FullModel, custom_collate_fn\n",
    "from trainer import Trainer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pympler import asizeof\n",
    "import gc\n",
    "import psutil\n",
    "\n",
    "\n",
    "def prepare(rank, world_size, train_data, test_data, batch_size=32, pin_memory=False, num_workers=0):\n",
    "    train_sampler = DistributedSampler(train_data, num_replicas=world_size, rank=rank, shuffle=True, drop_last=False)\n",
    "    train_dataloader = DataLoader(train_data, batch_size=batch_size, pin_memory=pin_memory, num_workers=num_workers, drop_last=False, shuffle=False, sampler=train_sampler, collate_fn=custom_collate_fn)\n",
    "\n",
    "    test_sampler = DistributedSampler(test_data, num_replicas=world_size, rank=rank, shuffle=False, drop_last=False)\n",
    "    test_dataloader = DataLoader(test_data, batch_size=batch_size, pin_memory=pin_memory, num_workers=num_workers, drop_last=False, shuffle=False, sampler=test_sampler, collate_fn=custom_collate_fn)\n",
    "    \n",
    "    return train_dataloader, test_dataloader, train_sampler\n",
    "\n",
    "def ddp_setup(rank, world_size):\n",
    "    os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "    os.environ[\"MASTER_PORT\"] = \"12355\"\n",
    "    backend = \"nccl\" if torch.cuda.is_available() else \"gloo\"\n",
    "    init_process_group(backend=backend, rank=rank, world_size=world_size)\n",
    "\n",
    "\n",
    "def main(rank:int, world_size:int, total_epochs: int, batch_size: int, lr, img_shape, energy_shape, spectrum_shape, feature_dim, output_dim, X_images, X_features, X_spectrums, X_energies, labels, labels_cols):\n",
    "    ddp_setup(rank, world_size)\n",
    "    torch.cuda.set_device(rank)\n",
    "\n",
    "    X_train_images, X_test_images, X_train_features, X_test_features, X_train_spectrums, X_test_spectrums, X_train_energies, X_test_energies, y_train, y_test = train_test_split(X_images, X_features, X_spectrums, X_energies, labels, test_size=0.2, random_state=42, stratify=labels[['Reverse', 'Forward', 'One_Shot_Intent', 'Loop_Intent', 'Drum', 'Hi Hat']])\n",
    "    \n",
    "    y_train_np = y_train[predictor_labels].to_numpy()\n",
    "    y_test_np = y_test[predictor_labels].to_numpy()\n",
    "    \n",
    "    train_dataset = MultiModalDataset(y_train['id'].to_numpy(), X_train_images, X_train_energies, X_train_spectrums, X_train_features, y_train_np)\n",
    "    val_dataset = MultiModalDataset(y_test['id'].to_numpy(), X_test_images, X_test_energies, X_test_spectrums, X_test_features, y_test_np)\n",
    "\n",
    "    \n",
    "    train_dataloader, val_dataloader, train_sampler = prepare(rank, world_size, train_dataset, val_dataset, batch_size=batch_size)\n",
    "    \n",
    "    model = FullModel(img_shape, energy_shape, spectrum_shape, feature_dim, output_dim)\n",
    "    model = nn.SyncBatchNorm.convert_sync_batchnorm(model)\n",
    "    model = model.to(rank)\n",
    "    model = DDP(model, device_ids=[rank], output_device=rank, find_unused_parameters=False)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    trainer = Trainer(model, train_dataloader, val_dataloader, rank, world_size)\n",
    "    gc.collect()\n",
    "\n",
    "    trainer.train(total_epochs, train_sampler, optimizer)\n",
    "    trainer.infer_best_model(predictor_labels, y_test)\n",
    "    \n",
    "    destroy_process_group()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    world_size = torch.cuda.device_count()\n",
    "\n",
    "    print('loading labels')\n",
    "    labels = joblib.load('/kaggle/input/classification-data/cut.joblib')\n",
    "    print('loaded labels')\n",
    "    \n",
    "    print('loading images')\n",
    "    images = joblib.load('/kaggle/input/classification-data/images.joblib')\n",
    "    print('loaded images')\n",
    "    \n",
    "    print('loading energies')\n",
    "    energies = joblib.load('/kaggle/input/classification-data/energies.joblib')\n",
    "    print('loaded energies')\n",
    "    \n",
    "    print('loading spectrums')\n",
    "    spectrums = joblib.load('/kaggle/input/classification-data/spectrums.joblib')\n",
    "    print('loaded spectrums')\n",
    "\n",
    "    labs = ['id', 'file_path', 'file_name'] + predictor_labels\n",
    "\n",
    "    images = np.asarray(images, dtype='object')\n",
    "    energies = np.asarray(energies, dtype='object')\n",
    "    spectrums = np.asarray(spectrums, dtype='object')\n",
    "    features = labels[features_labels].astype(np.float32).to_numpy()\n",
    "\n",
    "    img_shape = images[0][0].transpose(2, 0, 1).shape\n",
    "    energy_shape = (energies[0][0].shape)\n",
    "    spectrum_shape = (spectrums[0].shape[1], 1, spectrums[0].shape[2])\n",
    "    feature_dim = labels[features_labels].shape[-1]\n",
    "    output_dim = len(predictor_labels)\n",
    "\n",
    "    X_images = [torch.tensor(img, dtype=torch.float32).share_memory_() for img in images]\n",
    "    X_spectrums = [torch.tensor(spec, dtype=torch.float32).share_memory_() for spec in spectrums]\n",
    "    X_energies = [torch.tensor(energy, dtype=torch.float32).share_memory_() for energy in energies]\n",
    "    X_features = torch.tensor(features, dtype=torch.float32).share_memory_()\n",
    "    \n",
    "    total_epochs = 140\n",
    "    batch_size = int(16)\n",
    "    lr = 0.00064 * 1.01\n",
    "    \n",
    "    print(f'world size: {world_size}')\n",
    "\n",
    "    del images, energies, spectrums, features  # the joblib objects\n",
    "    gc.collect()\n",
    "    \n",
    "    mp.spawn(main, args=(world_size, total_epochs, batch_size, lr, img_shape, energy_shape, spectrum_shape, feature_dim, output_dim, X_images, X_features, X_spectrums, X_energies, labels, labs), nprocs=world_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e78dcd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T00:40:00.818710Z",
     "iopub.status.busy": "2025-08-20T00:40:00.818450Z",
     "iopub.status.idle": "2025-08-20T02:46:59.344558Z",
     "shell.execute_reply": "2025-08-20T02:46:59.343669Z"
    },
    "papermill": {
     "duration": 7618.530925,
     "end_time": "2025-08-20T02:46:59.346404",
     "exception": false,
     "start_time": "2025-08-20T00:40:00.815479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading labels\r\n",
      "loaded labels\r\n",
      "loading images\r\n",
      "loaded images\r\n",
      "loading energies\r\n",
      "loaded energies\r\n",
      "loading spectrums\r\n",
      "loaded spectrums\r\n",
      "world size: 2\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 1/140\r\n",
      "Train Loss: 29.8568 Train acc: 0.0138 Train AUC: 0.6595\r\n",
      "Val   Loss: 27.6991 Val   acc: 0.0273 Val   AUC: 0.6967\r\n",
      "Accuracy increased to 0.0273 from 0.0000. Saved copy of new weights\r\n",
      "max mem used on gpu0: 3.5882GB\r\n",
      "max mem used on gpu1: 1.8541GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 2/140\r\n",
      "Train Loss: 26.2306 Train acc: 0.0385 Train AUC: 0.7040\r\n",
      "Val   Loss: 24.7915 Val   acc: 0.0664 Val   AUC: 0.7094\r\n",
      "Accuracy increased to 0.0664 from 0.0273. Saved copy of new weights\r\n",
      "max mem used on gpu1: 3.3196GB\r\n",
      "max mem used on gpu0: 3.5882GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 3/140\r\n",
      "Train Loss: 23.9707 Train acc: 0.0636 Train AUC: 0.7163\r\n",
      "Val   Loss: 21.0145 Val   acc: 0.1295 Val   AUC: 0.7365\r\n",
      "Accuracy increased to 0.1295 from 0.0664. Saved copy of new weights\r\n",
      "max mem used on gpu1: 3.5759GB\r\n",
      "max mem used on gpu0: 3.5882GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 4/140\r\n",
      "Train Loss: 20.0115 Train acc: 0.0837 Train AUC: 0.7311\r\n",
      "Val   Loss: 18.0791 Val   acc: 0.0748 Val   AUC: 0.7352\r\n",
      "max mem used on gpu1: 3.5759GB\r\n",
      "max mem used on gpu0: 3.5882GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 5/140\r\n",
      "Train Loss: 10.4543 Train acc: 0.0949 Train AUC: 0.7452\r\n",
      "Val   Loss: 0.4834 Val   acc: 0.1429 Val   AUC: 0.8250\r\n",
      "Accuracy increased to 0.1429 from 0.1295. Saved copy of new weights\r\n",
      "max mem used on gpu1: 3.5759GB\r\n",
      "max mem used on gpu0: 3.5882GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 6/140\r\n",
      "Train Loss: 0.7591 Train acc: 0.1034 Train AUC: 0.7815\r\n",
      "Val   Loss: 0.4067 Val   acc: 0.1724 Val   AUC: 0.8464\r\n",
      "Accuracy increased to 0.1724 from 0.1429. Saved copy of new weights\r\n",
      "max mem used on gpu1: 3.5759GB\r\n",
      "max mem used on gpu0: 3.5882GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 7/140\r\n",
      "Train Loss: 0.5407 Train acc: 0.1486 Train AUC: 0.8137\r\n",
      "Val   Loss: 0.3621 Val   acc: 0.2852 Val   AUC: 0.8578\r\n",
      "Accuracy increased to 0.2852 from 0.1724. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 8/140\r\n",
      "Train Loss: 0.4639 Train acc: 0.1871 Train AUC: 0.8340\r\n",
      "Val   Loss: 0.3628 Val   acc: 0.2985 Val   AUC: 0.8503\r\n",
      "Accuracy increased to 0.2985 from 0.2852. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 9/140\r\n",
      "Train Loss: 0.3999 Train acc: 0.2356 Train AUC: 0.8502\r\n",
      "Val   Loss: 0.3768 Val   acc: 0.3465 Val   AUC: 0.8699\r\n",
      "Accuracy increased to 0.3465 from 0.2985. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 10/140\r\n",
      "Train Loss: 0.3585 Train acc: 0.3031 Train AUC: 0.8710\r\n",
      "Val   Loss: 0.3037 Val   acc: 0.4978 Val   AUC: 0.9191\r\n",
      "Accuracy increased to 0.4978 from 0.3465. Saved copy of new weights\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 11/140\r\n",
      "Train Loss: 0.3169 Train acc: 0.3927 Train AUC: 0.9030\r\n",
      "Val   Loss: 0.2731 Val   acc: 0.5815 Val   AUC: 0.9402\r\n",
      "Accuracy increased to 0.5815 from 0.4978. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 12/140\r\n",
      "Train Loss: 0.2886 Train acc: 0.4958 Train AUC: 0.9270\r\n",
      "Val   Loss: 0.2798 Val   acc: 0.5307 Val   AUC: 0.9353\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 13/140\r\n",
      "Train Loss: 0.2506 Train acc: 0.5826 Train AUC: 0.9460\r\n",
      "Val   Loss: 0.2417 Val   acc: 0.6819 Val   AUC: 0.9597\r\n",
      "Accuracy increased to 0.6819 from 0.5815. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 14/140\r\n",
      "Train Loss: 0.2308 Train acc: 0.6394 Train AUC: 0.9565\r\n",
      "Val   Loss: 0.5182 Val   acc: 0.2812 Val   AUC: 0.8496\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 15/140\r\n",
      "Train Loss: 0.2050 Train acc: 0.6672 Train AUC: 0.9618\r\n",
      "Val   Loss: 0.1725 Val   acc: 0.7606 Val   AUC: 0.9763\r\n",
      "Accuracy increased to 0.7606 from 0.6819. Saved copy of new weights\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 16/140\r\n",
      "Train Loss: 0.1979 Train acc: 0.6822 Train AUC: 0.9652\r\n",
      "Val   Loss: 0.1703 Val   acc: 0.7483 Val   AUC: 0.9753\r\n",
      "max mem used on gpu1: 3.9646GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 17/140\r\n",
      "Train Loss: 0.1870 Train acc: 0.7095 Train AUC: 0.9678\r\n",
      "Val   Loss: 0.1419 Val   acc: 0.7785 Val   AUC: 0.9822\r\n",
      "Accuracy increased to 0.7785 from 0.7606. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 18/140\r\n",
      "Train Loss: 0.1734 Train acc: 0.7167 Train AUC: 0.9705\r\n",
      "Val   Loss: 0.1366 Val   acc: 0.7840 Val   AUC: 0.9820\r\n",
      "Accuracy increased to 0.7840 from 0.7785. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 19/140\r\n",
      "Train Loss: 0.1674 Train acc: 0.7346 Train AUC: 0.9734\r\n",
      "Val   Loss: 0.1302 Val   acc: 0.8080 Val   AUC: 0.9850\r\n",
      "Accuracy increased to 0.8080 from 0.7840. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 20/140\r\n",
      "Train Loss: 0.1572 Train acc: 0.7453 Train AUC: 0.9748\r\n",
      "Val   Loss: 0.1226 Val   acc: 0.8064 Val   AUC: 0.9864\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 21/140\r\n",
      "Train Loss: 0.1493 Train acc: 0.7628 Train AUC: 0.9778\r\n",
      "Val   Loss: 0.5937 Val   acc: 0.2773 Val   AUC: 0.8588\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 22/140\r\n",
      "Train Loss: 0.1469 Train acc: 0.7710 Train AUC: 0.9798\r\n",
      "Val   Loss: 1.0842 Val   acc: 0.3047 Val   AUC: 0.8635\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 23/140\r\n",
      "Train Loss: 0.1317 Train acc: 0.7884 Train AUC: 0.9829\r\n",
      "Val   Loss: 0.1076 Val   acc: 0.8426 Val   AUC: 0.9906\r\n",
      "Accuracy increased to 0.8426 from 0.8080. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 24/140\r\n",
      "Train Loss: 0.1234 Train acc: 0.8077 Train AUC: 0.9857\r\n",
      "Val   Loss: 0.0965 Val   acc: 0.8689 Val   AUC: 0.9923\r\n",
      "Accuracy increased to 0.8689 from 0.8426. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 25/140\r\n",
      "Train Loss: 0.1130 Train acc: 0.8369 Train AUC: 0.9890\r\n",
      "Val   Loss: 0.0877 Val   acc: 0.8795 Val   AUC: 0.9935\r\n",
      "Accuracy increased to 0.8795 from 0.8689. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 26/140\r\n",
      "Train Loss: 0.1035 Train acc: 0.8603 Train AUC: 0.9910\r\n",
      "Val   Loss: 0.0787 Val   acc: 0.8834 Val   AUC: 0.9954\r\n",
      "Accuracy increased to 0.8834 from 0.8795. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 27/140\r\n",
      "Train Loss: 0.0968 Train acc: 0.8691 Train AUC: 0.9922\r\n",
      "Val   Loss: 0.5591 Val   acc: 0.3359 Val   AUC: 0.8864\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 28/140\r\n",
      "Train Loss: 0.0887 Train acc: 0.8787 Train AUC: 0.9934\r\n",
      "Val   Loss: 0.5689 Val   acc: 0.3225 Val   AUC: 0.8679\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 29/140\r\n",
      "Train Loss: 0.0818 Train acc: 0.8891 Train AUC: 0.9940\r\n",
      "Val   Loss: 0.1142 Val   acc: 0.8421 Val   AUC: 0.9917\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 30/140\r\n",
      "Train Loss: 0.0775 Train acc: 0.8984 Train AUC: 0.9947\r\n",
      "Val   Loss: 0.0834 Val   acc: 0.8834 Val   AUC: 0.9949\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 31/140\r\n",
      "Train Loss: 0.0742 Train acc: 0.8988 Train AUC: 0.9952\r\n",
      "Val   Loss: 0.1331 Val   acc: 0.8382 Val   AUC: 0.9904\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 32/140\r\n",
      "Train Loss: 0.0671 Train acc: 0.9068 Train AUC: 0.9961\r\n",
      "Val   Loss: 0.0858 Val   acc: 0.8929 Val   AUC: 0.9948\r\n",
      "Accuracy increased to 0.8929 from 0.8834. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 33/140\r\n",
      "Train Loss: 0.0601 Train acc: 0.9177 Train AUC: 0.9966\r\n",
      "Val   Loss: 0.0530 Val   acc: 0.9381 Val   AUC: 0.9975\r\n",
      "Accuracy increased to 0.9381 from 0.8929. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 34/140\r\n",
      "Train Loss: 0.0572 Train acc: 0.9216 Train AUC: 0.9970\r\n",
      "Val   Loss: 0.7961 Val   acc: 0.2913 Val   AUC: 0.8576\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 35/140\r\n",
      "Train Loss: 0.0604 Train acc: 0.9167 Train AUC: 0.9966\r\n",
      "Val   Loss: 0.0567 Val   acc: 0.9364 Val   AUC: 0.9973\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 36/140\r\n",
      "Train Loss: 0.0514 Train acc: 0.9266 Train AUC: 0.9975\r\n",
      "Val   Loss: 0.0547 Val   acc: 0.9369 Val   AUC: 0.9977\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 37/140\r\n",
      "Train Loss: 0.0497 Train acc: 0.9329 Train AUC: 0.9975\r\n",
      "Val   Loss: 0.0497 Val   acc: 0.9381 Val   AUC: 0.9979\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 38/140\r\n",
      "Train Loss: 0.0480 Train acc: 0.9350 Train AUC: 0.9978\r\n",
      "Val   Loss: 0.0502 Val   acc: 0.9392 Val   AUC: 0.9982\r\n",
      "Accuracy increased to 0.9392 from 0.9381. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 39/140\r\n",
      "Train Loss: 0.0421 Train acc: 0.9419 Train AUC: 0.9983\r\n",
      "Val   Loss: 0.0656 Val   acc: 0.9375 Val   AUC: 0.9975\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 40/140\r\n",
      "Train Loss: 0.0501 Train acc: 0.9393 Train AUC: 0.9978\r\n",
      "Val   Loss: 0.0500 Val   acc: 0.9403 Val   AUC: 0.9981\r\n",
      "Accuracy increased to 0.9403 from 0.9392. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 41/140\r\n",
      "Train Loss: 0.0415 Train acc: 0.9429 Train AUC: 0.9981\r\n",
      "Val   Loss: 0.0493 Val   acc: 0.9442 Val   AUC: 0.9982\r\n",
      "Accuracy increased to 0.9442 from 0.9403. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 42/140\r\n",
      "Train Loss: 0.0441 Train acc: 0.9445 Train AUC: 0.9983\r\n",
      "Val   Loss: 3.1236 Val   acc: 0.2751 Val   AUC: 0.8634\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 43/140\r\n",
      "Train Loss: 0.0443 Train acc: 0.9431 Train AUC: 0.9982\r\n",
      "Val   Loss: 0.3163 Val   acc: 0.7533 Val   AUC: 0.9917\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 44/140\r\n",
      "Train Loss: 0.0364 Train acc: 0.9443 Train AUC: 0.9986\r\n",
      "Val   Loss: 0.0599 Val   acc: 0.9392 Val   AUC: 0.9980\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 45/140\r\n",
      "Train Loss: 0.0397 Train acc: 0.9413 Train AUC: 0.9985\r\n",
      "Val   Loss: 1.0501 Val   acc: 0.2980 Val   AUC: 0.8692\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 46/140\r\n",
      "Train Loss: 0.0406 Train acc: 0.9413 Train AUC: 0.9984\r\n",
      "Val   Loss: 0.6705 Val   acc: 0.3058 Val   AUC: 0.8583\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 47/140\r\n",
      "Train Loss: 0.0449 Train acc: 0.9421 Train AUC: 0.9984\r\n",
      "Val   Loss: 0.0533 Val   acc: 0.9353 Val   AUC: 0.9976\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 48/140\r\n",
      "Train Loss: 0.0361 Train acc: 0.9491 Train AUC: 0.9987\r\n",
      "Val   Loss: 0.0532 Val   acc: 0.9353 Val   AUC: 0.9978\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 49/140\r\n",
      "Train Loss: 0.0360 Train acc: 0.9493 Train AUC: 0.9987\r\n",
      "Val   Loss: 0.0445 Val   acc: 0.9470 Val   AUC: 0.9986\r\n",
      "Accuracy increased to 0.9470 from 0.9442. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 50/140\r\n",
      "Train Loss: 0.0377 Train acc: 0.9459 Train AUC: 0.9987\r\n",
      "Val   Loss: 0.0491 Val   acc: 0.9487 Val   AUC: 0.9984\r\n",
      "Accuracy increased to 0.9487 from 0.9470. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 51/140\r\n",
      "Train Loss: 0.0345 Train acc: 0.9492 Train AUC: 0.9987\r\n",
      "Val   Loss: 0.0523 Val   acc: 0.9453 Val   AUC: 0.9981\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 52/140\r\n",
      "Train Loss: 0.0348 Train acc: 0.9509 Train AUC: 0.9988\r\n",
      "Val   Loss: 0.0379 Val   acc: 0.9487 Val   AUC: 0.9986\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 53/140\r\n",
      "Train Loss: 0.0317 Train acc: 0.9510 Train AUC: 0.9990\r\n",
      "Val   Loss: 0.0437 Val   acc: 0.9498 Val   AUC: 0.9986\r\n",
      "Accuracy increased to 0.9498 from 0.9487. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 54/140\r\n",
      "Train Loss: 0.0346 Train acc: 0.9499 Train AUC: 0.9988\r\n",
      "Val   Loss: 0.0620 Val   acc: 0.9397 Val   AUC: 0.9982\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 55/140\r\n",
      "Train Loss: 0.0296 Train acc: 0.9552 Train AUC: 0.9991\r\n",
      "Val   Loss: 0.0539 Val   acc: 0.9436 Val   AUC: 0.9984\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 56/140\r\n",
      "Train Loss: 0.0299 Train acc: 0.9556 Train AUC: 0.9989\r\n",
      "Val   Loss: 0.0386 Val   acc: 0.9526 Val   AUC: 0.9985\r\n",
      "Accuracy increased to 0.9526 from 0.9498. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 57/140\r\n",
      "Train Loss: 0.0276 Train acc: 0.9553 Train AUC: 0.9992\r\n",
      "Val   Loss: 0.0435 Val   acc: 0.9542 Val   AUC: 0.9988\r\n",
      "Accuracy increased to 0.9542 from 0.9526. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 58/140\r\n",
      "Train Loss: 0.0302 Train acc: 0.9565 Train AUC: 0.9990\r\n",
      "Val   Loss: 0.0372 Val   acc: 0.9559 Val   AUC: 0.9989\r\n",
      "Accuracy increased to 0.9559 from 0.9542. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 59/140\r\n",
      "Train Loss: 0.0300 Train acc: 0.9555 Train AUC: 0.9991\r\n",
      "Val   Loss: 0.4088 Val   acc: 0.6507 Val   AUC: 0.9784\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 60/140\r\n",
      "Train Loss: 0.0235 Train acc: 0.9604 Train AUC: 0.9993\r\n",
      "Val   Loss: 0.0372 Val   acc: 0.9559 Val   AUC: 0.9987\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 61/140\r\n",
      "Train Loss: 0.0278 Train acc: 0.9556 Train AUC: 0.9992\r\n",
      "Val   Loss: 0.0480 Val   acc: 0.9414 Val   AUC: 0.9983\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 62/140\r\n",
      "Train Loss: 0.0255 Train acc: 0.9595 Train AUC: 0.9993\r\n",
      "Val   Loss: 0.0395 Val   acc: 0.9515 Val   AUC: 0.9988\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 63/140\r\n",
      "Train Loss: 0.0271 Train acc: 0.9586 Train AUC: 0.9992\r\n",
      "Val   Loss: 0.0638 Val   acc: 0.9263 Val   AUC: 0.9977\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 64/140\r\n",
      "Train Loss: 0.0290 Train acc: 0.9608 Train AUC: 0.9993\r\n",
      "Val   Loss: 0.0577 Val   acc: 0.9464 Val   AUC: 0.9986\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 65/140\r\n",
      "Train Loss: 0.0248 Train acc: 0.9630 Train AUC: 0.9993\r\n",
      "Val   Loss: 0.0419 Val   acc: 0.9509 Val   AUC: 0.9987\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 66/140\r\n",
      "Train Loss: 0.0257 Train acc: 0.9625 Train AUC: 0.9993\r\n",
      "Val   Loss: 0.0420 Val   acc: 0.9609 Val   AUC: 0.9988\r\n",
      "Accuracy increased to 0.9609 from 0.9559. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 67/140\r\n",
      "Train Loss: 0.0230 Train acc: 0.9637 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0394 Val   acc: 0.9531 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 68/140\r\n",
      "Train Loss: 0.0250 Train acc: 0.9604 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0432 Val   acc: 0.9587 Val   AUC: 0.9986\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 69/140\r\n",
      "Train Loss: 0.0275 Train acc: 0.9602 Train AUC: 0.9992\r\n",
      "Val   Loss: 1.5970 Val   acc: 0.2958 Val   AUC: 0.8444\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 70/140\r\n",
      "Train Loss: 0.0244 Train acc: 0.9630 Train AUC: 0.9994\r\n",
      "Val   Loss: 1.7425 Val   acc: 0.3504 Val   AUC: 0.9111\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 71/140\r\n",
      "Train Loss: 0.0316 Train acc: 0.9581 Train AUC: 0.9991\r\n",
      "Val   Loss: 0.0630 Val   acc: 0.9308 Val   AUC: 0.9978\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 72/140\r\n",
      "Train Loss: 0.0267 Train acc: 0.9590 Train AUC: 0.9992\r\n",
      "Val   Loss: 0.0816 Val   acc: 0.9124 Val   AUC: 0.9968\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 73/140\r\n",
      "Train Loss: 0.0231 Train acc: 0.9653 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0480 Val   acc: 0.9548 Val   AUC: 0.9986\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 74/140\r\n",
      "Train Loss: 0.0245 Train acc: 0.9609 Train AUC: 0.9994\r\n",
      "Val   Loss: 1.2457 Val   acc: 0.2494 Val   AUC: 0.8352\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 75/140\r\n",
      "Train Loss: 0.0246 Train acc: 0.9632 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0437 Val   acc: 0.9554 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 76/140\r\n",
      "Train Loss: 0.0249 Train acc: 0.9598 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0689 Val   acc: 0.9308 Val   AUC: 0.9977\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 77/140\r\n",
      "Train Loss: 0.0310 Train acc: 0.9602 Train AUC: 0.9993\r\n",
      "Val   Loss: 0.0414 Val   acc: 0.9492 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 78/140\r\n",
      "Train Loss: 0.0240 Train acc: 0.9626 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0551 Val   acc: 0.9548 Val   AUC: 0.9984\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 79/140\r\n",
      "Train Loss: 0.0220 Train acc: 0.9653 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0597 Val   acc: 0.9481 Val   AUC: 0.9985\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 80/140\r\n",
      "Train Loss: 0.0208 Train acc: 0.9657 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0547 Val   acc: 0.9576 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 81/140\r\n",
      "Train Loss: 0.0208 Train acc: 0.9657 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0403 Val   acc: 0.9548 Val   AUC: 0.9992\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 82/140\r\n",
      "Train Loss: 0.0219 Train acc: 0.9653 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0556 Val   acc: 0.9425 Val   AUC: 0.9987\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 83/140\r\n",
      "Train Loss: 0.0273 Train acc: 0.9572 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0429 Val   acc: 0.9576 Val   AUC: 0.9989\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 84/140\r\n",
      "Train Loss: 0.0254 Train acc: 0.9690 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0379 Val   acc: 0.9621 Val   AUC: 0.9991\r\n",
      "Accuracy increased to 0.9621 from 0.9609. Saved copy of new weights\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 85/140\r\n",
      "Train Loss: 0.0233 Train acc: 0.9640 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0500 Val   acc: 0.9643 Val   AUC: 0.9988\r\n",
      "Accuracy increased to 0.9643 from 0.9621. Saved copy of new weights\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 86/140\r\n",
      "Train Loss: 0.0201 Train acc: 0.9690 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0394 Val   acc: 0.9581 Val   AUC: 0.9990\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 87/140\r\n",
      "Train Loss: 0.0203 Train acc: 0.9680 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0374 Val   acc: 0.9593 Val   AUC: 0.9991\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 88/140\r\n",
      "Train Loss: 0.0242 Train acc: 0.9666 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0421 Val   acc: 0.9581 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 89/140\r\n",
      "Train Loss: 0.0201 Train acc: 0.9657 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.5342 Val   acc: 0.3281 Val   AUC: 0.8712\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 90/140\r\n",
      "Train Loss: 0.0214 Train acc: 0.9675 Train AUC: 0.9995\r\n",
      "Val   Loss: 2.5611 Val   acc: 0.2260 Val   AUC: 0.8645\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 91/140\r\n",
      "Train Loss: 0.0290 Train acc: 0.9648 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.8491 Val   acc: 0.2790 Val   AUC: 0.8662\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 92/140\r\n",
      "Train Loss: 0.0193 Train acc: 0.9680 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0456 Val   acc: 0.9615 Val   AUC: 0.9989\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 93/140\r\n",
      "Train Loss: 0.0207 Train acc: 0.9653 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0382 Val   acc: 0.9604 Val   AUC: 0.9989\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 94/140\r\n",
      "Train Loss: 0.0203 Train acc: 0.9660 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0458 Val   acc: 0.9576 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 95/140\r\n",
      "Train Loss: 0.0169 Train acc: 0.9713 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0505 Val   acc: 0.9570 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 96/140\r\n",
      "Train Loss: 0.0185 Train acc: 0.9693 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0652 Val   acc: 0.9358 Val   AUC: 0.9980\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 97/140\r\n",
      "Train Loss: 0.0174 Train acc: 0.9692 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0643 Val   acc: 0.9520 Val   AUC: 0.9986\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 98/140\r\n",
      "Train Loss: 0.0149 Train acc: 0.9743 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.7768 Val   acc: 0.3203 Val   AUC: 0.8827\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 99/140\r\n",
      "Train Loss: 0.0356 Train acc: 0.9665 Train AUC: 0.9993\r\n",
      "Val   Loss: 1.2234 Val   acc: 0.2383 Val   AUC: 0.8571\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 100/140\r\n",
      "Train Loss: 0.0166 Train acc: 0.9701 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0770 Val   acc: 0.9286 Val   AUC: 0.9979\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 101/140\r\n",
      "Train Loss: 0.0228 Train acc: 0.9687 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.2520 Val   acc: 0.6083 Val   AUC: 0.9820\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 102/140\r\n",
      "Train Loss: 0.0206 Train acc: 0.9694 Train AUC: 0.9996\r\n",
      "Val   Loss: 2.0607 Val   acc: 0.2037 Val   AUC: 0.8494\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 103/140\r\n",
      "Train Loss: 0.0205 Train acc: 0.9704 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0483 Val   acc: 0.9570 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 104/140\r\n",
      "Train Loss: 0.0174 Train acc: 0.9715 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0420 Val   acc: 0.9643 Val   AUC: 0.9991\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 105/140\r\n",
      "Train Loss: 0.0208 Train acc: 0.9675 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0664 Val   acc: 0.9526 Val   AUC: 0.9986\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 106/140\r\n",
      "Train Loss: 0.0301 Train acc: 0.9696 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.2777 Val   acc: 0.5865 Val   AUC: 0.9558\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 107/140\r\n",
      "Train Loss: 0.0213 Train acc: 0.9714 Train AUC: 0.9995\r\n",
      "Val   Loss: 0.0424 Val   acc: 0.9609 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 108/140\r\n",
      "Train Loss: 0.0174 Train acc: 0.9707 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0459 Val   acc: 0.9609 Val   AUC: 0.9991\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 109/140\r\n",
      "Train Loss: 0.0181 Train acc: 0.9725 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0371 Val   acc: 0.9643 Val   AUC: 0.9993\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 110/140\r\n",
      "Train Loss: 0.0188 Train acc: 0.9732 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0482 Val   acc: 0.9604 Val   AUC: 0.9989\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 111/140\r\n",
      "Train Loss: 0.0145 Train acc: 0.9729 Train AUC: 0.9998\r\n",
      "Val   Loss: 0.1774 Val   acc: 0.8242 Val   AUC: 0.9909\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 112/140\r\n",
      "Train Loss: 0.0159 Train acc: 0.9752 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0488 Val   acc: 0.9554 Val   AUC: 0.9989\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 113/140\r\n",
      "Train Loss: 0.0186 Train acc: 0.9729 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0426 Val   acc: 0.9498 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 114/140\r\n",
      "Train Loss: 0.0171 Train acc: 0.9718 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0513 Val   acc: 0.9593 Val   AUC: 0.9986\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 115/140\r\n",
      "Train Loss: 0.0165 Train acc: 0.9721 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.1521 Val   acc: 0.8739 Val   AUC: 0.9968\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 116/140\r\n",
      "Train Loss: 0.0163 Train acc: 0.9749 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0524 Val   acc: 0.9598 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 117/140\r\n",
      "Train Loss: 0.0160 Train acc: 0.9731 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0501 Val   acc: 0.9565 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 118/140\r\n",
      "Train Loss: 0.0151 Train acc: 0.9729 Train AUC: 0.9998\r\n",
      "Val   Loss: 0.0777 Val   acc: 0.9431 Val   AUC: 0.9983\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 119/140\r\n",
      "Train Loss: 0.0155 Train acc: 0.9757 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0591 Val   acc: 0.9548 Val   AUC: 0.9987\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 120/140\r\n",
      "Train Loss: 0.0219 Train acc: 0.9696 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0601 Val   acc: 0.9531 Val   AUC: 0.9987\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 121/140\r\n",
      "Train Loss: 0.0171 Train acc: 0.9718 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0436 Val   acc: 0.9581 Val   AUC: 0.9991\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 122/140\r\n",
      "Train Loss: 0.0248 Train acc: 0.9683 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.7508 Val   acc: 0.3030 Val   AUC: 0.8564\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 123/140\r\n",
      "Train Loss: 0.0163 Train acc: 0.9731 Train AUC: 0.9997\r\n",
      "Val   Loss: 1.0658 Val   acc: 0.3019 Val   AUC: 0.8698\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 124/140\r\n",
      "Train Loss: 0.0282 Train acc: 0.9694 Train AUC: 0.9994\r\n",
      "Val   Loss: 0.0567 Val   acc: 0.9475 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 125/140\r\n",
      "Train Loss: 0.0205 Train acc: 0.9707 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0501 Val   acc: 0.9554 Val   AUC: 0.9991\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 126/140\r\n",
      "Train Loss: 0.0146 Train acc: 0.9756 Train AUC: 0.9998\r\n",
      "Val   Loss: 0.0564 Val   acc: 0.9565 Val   AUC: 0.9990\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 127/140\r\n",
      "Train Loss: 0.0165 Train acc: 0.9715 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.3649 Val   acc: 0.7031 Val   AUC: 0.9823\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 128/140\r\n",
      "Train Loss: 0.0219 Train acc: 0.9694 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0494 Val   acc: 0.9503 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 129/140\r\n",
      "Train Loss: 0.0151 Train acc: 0.9745 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0454 Val   acc: 0.9587 Val   AUC: 0.9990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 130/140\r\n",
      "Train Loss: 0.0163 Train acc: 0.9740 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0441 Val   acc: 0.9632 Val   AUC: 0.9989\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 131/140\r\n",
      "Train Loss: 0.0163 Train acc: 0.9756 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0533 Val   acc: 0.9548 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 132/140\r\n",
      "Train Loss: 0.0124 Train acc: 0.9764 Train AUC: 0.9998\r\n",
      "Val   Loss: 0.5942 Val   acc: 0.4046 Val   AUC: 0.8990\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 133/140\r\n",
      "Train Loss: 0.0191 Train acc: 0.9753 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0470 Val   acc: 0.9581 Val   AUC: 0.9991\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 134/140\r\n",
      "Train Loss: 0.0144 Train acc: 0.9759 Train AUC: 0.9998\r\n",
      "Val   Loss: 0.0778 Val   acc: 0.9487 Val   AUC: 0.9984\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 135/140\r\n",
      "Train Loss: 0.0174 Train acc: 0.9704 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.7471 Val   acc: 0.2796 Val   AUC: 0.8584\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 136/140\r\n",
      "Train Loss: 0.0206 Train acc: 0.9718 Train AUC: 0.9996\r\n",
      "Val   Loss: 0.0548 Val   acc: 0.9542 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 137/140\r\n",
      "Train Loss: 0.0207 Train acc: 0.9718 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0502 Val   acc: 0.9559 Val   AUC: 0.9987\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 138/140\r\n",
      "Train Loss: 0.0166 Train acc: 0.9715 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0469 Val   acc: 0.9570 Val   AUC: 0.9988\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 139/140\r\n",
      "Train Loss: 0.0176 Train acc: 0.9749 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.6901 Val   acc: 0.3895 Val   AUC: 0.8730\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "------------------------------------------------------------\r\n",
      "Epoch: 140/140\r\n",
      "Train Loss: 0.0221 Train acc: 0.9746 Train AUC: 0.9997\r\n",
      "Val   Loss: 0.0660 Val   acc: 0.9637 Val   AUC: 0.9988\r\n",
      "max mem used on gpu1: 4.2664GB\r\n",
      "max mem used on gpu0: 5.0453GB\r\n",
      "Best Epoch : 85 - accuracy: 0.9642857313156128\r\n",
      "F1 Score: 0.9914124210250502\r\n",
      "                 precision    recall  f1-score   support\r\n",
      "\r\n",
      "        Reverse       0.99      0.98      0.98       901\r\n",
      "        Forward       0.99      0.99      0.99       897\r\n",
      "One_Shot_Intent       1.00      1.00      1.00       897\r\n",
      "    Loop_Intent       1.00      1.00      1.00       895\r\n",
      "           Drum       0.99      0.99      0.99       600\r\n",
      "     Percussion       1.00      1.00      1.00      1193\r\n",
      "           Kick       0.99      0.99      0.99       599\r\n",
      "           Clap       0.98      0.98      0.98       595\r\n",
      "         Hi Hat       0.98      0.98      0.98       598\r\n",
      "\r\n",
      "      micro avg       0.99      0.99      0.99      7175\r\n",
      "      macro avg       0.99      0.99      0.99      7175\r\n",
      "   weighted avg       0.99      0.99      0.99      7175\r\n",
      "    samples avg       0.99      0.99      0.99      7175\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python3 ddp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8723c10",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-20T02:46:59.370119Z",
     "iopub.status.busy": "2025-08-20T02:46:59.369830Z",
     "iopub.status.idle": "2025-08-20T02:46:59.618089Z",
     "shell.execute_reply": "2025-08-20T02:46:59.617268Z"
    },
    "papermill": {
     "duration": 0.261585,
     "end_time": "2025-08-20T02:46:59.619649",
     "exception": false,
     "start_time": "2025-08-20T02:46:59.358064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_weights.pth  even_loop_oneshot_2.xlsx  __notebook__.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.remove(\"/kaggle/working/data.py\")\n",
    "os.remove(\"/kaggle/working/ddp.py\")\n",
    "os.remove(\"/kaggle/working/model.py\")\n",
    "os.remove(\"/kaggle/working/trainer.py\")\n",
    "\n",
    "!rm -rf /kaggle/working/__pycache__\n",
    "!ls /kaggle/working/"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8045441,
     "isSourceIdPinned": true,
     "sourceId": 12757808,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 424604,
     "modelInstanceId": 406701,
     "sourceId": 523776,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31090,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 7623.764197,
   "end_time": "2025-08-20T02:46:59.955665",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-08-20T00:39:56.191468",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
